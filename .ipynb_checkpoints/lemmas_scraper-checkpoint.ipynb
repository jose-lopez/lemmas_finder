{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Lemmas_scraper: A jupyter notebook to scrap lemmas from:\n",
    "https://logeion.uchicago.edu/morpho/\n",
    "\n",
    "Created on 21 jul. 2023\n",
    "\n",
    "@authors: Jose Lopez, Jacobo Myerston\n",
    "\n",
    "@email: josesmooth@gmail.com\n",
    "\n",
    "@email: jmyerston@gmail.com\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdmAbdbXVG0F",
    "outputId": "a13ff8f7-dd43-4f7b-a43a-82868bf07027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: requests in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (2023.7.22)\n",
      "Requirement already satisfied: selenium in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: pandas in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "ERROR: unknown command \"instal\" - maybe you meant \"install\"\n",
      "Requirement already satisfied: ipywidgets in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (8.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: backcall in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: jupyterlab_widgets in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (3.0.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install webdriver-manager\n",
    "! pip install selenium\n",
    "! pip install pandas\n",
    "! pip instal tqdm\n",
    "! pip install ipywidgets\n",
    "! pip install jupyterlab_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BduH8VVtXxf4"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from urllib.parse import quote\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy.core.numeric import nan\n",
    "import re\n",
    "from _io import TextIOWrapper\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_browser():\n",
    "\n",
    "    \"\"\"\n",
    "    This is a function to check if Google Chrome is available.\n",
    "    \"\"\"    \n",
    "\n",
    "    print(f'Checking Google Chrome installation....' + \"\\n\")\n",
    "\n",
    "    with os.popen(\"google-chrome --version\") as f1:\n",
    "        browser = f1.readlines()\n",
    "\n",
    "    if len(browser):\n",
    "\n",
    "        version = browser[0].split(\" \")[-2]\n",
    "\n",
    "        print(\"Google Chrome is available: \")\n",
    "        print(f'Version: {version}' + \"\\n\")\n",
    "        \n",
    "    else:\n",
    "\n",
    "        print(f'Google Chrome is not available. Please install it as follows.' + \"\\n\")\n",
    "\n",
    "        print(f'wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb' + \"\\n\")\n",
    "\n",
    "        print(f'sudo apt install ./google-chrome-stable_current_amd64.deb' + \"\\n\")\n",
    "\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7kcwArXWX2AB"
   },
   "outputs": [],
   "source": [
    "def get_browser() -> webdriver:\n",
    "    \n",
    "    \"\"\"\n",
    "    This method gets the browser and the related Seleniums's driver,\n",
    "    in order to scrap the lemmas. The method also offers a guide to\n",
    "    follow, in case the version of your current browser doesn't have a\n",
    "    a compatible Seleniums's driver.\n",
    "    \"\"\"\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    options.add_argument('--no-sandbox')\n",
    "    \n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    options.add_argument(\"--headless=new\")\n",
    "    \n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "    \n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    \n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    \n",
    "    options.add_argument(\"--ignore-certificate-errors\")\n",
    "    \n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "    \n",
    "    options.add_argument(\"--no-default-browser-check\")\n",
    "    \n",
    "    options.add_argument(\"--no-first-run\")\n",
    "    \n",
    "    options.add_argument(\"--no-proxy-server\")\n",
    "    \n",
    "    options.add_argument(\"--disable-blink-features=AutomationController\")\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    except Exception as e:\n",
    "    \n",
    "        MSG = str(e)\n",
    "    \n",
    "        if MSG.startswith(\"No such driver version\"):\n",
    "    \n",
    "            chrome_deb_url = \"https://drive.google.com/file/d/1rw-T5jVOWuzhbbAmspLfzntt0xnJIuFe/view?usp=drive_link\"\n",
    "    \n",
    "            print(f'Please, downgrade your chrome\\'s version in order to find a Selenium\\'s webdriver.' + \"\\n\")\n",
    "    \n",
    "            print(f'This is a guide to follow: ' + \"\\n\")\n",
    "    \n",
    "            print(f'Get an older and safe .deb chrome installer from here:' + \"\\n\")\n",
    "    \n",
    "            print(f'{chrome_deb_url}' + \"\\n\")\n",
    "    \n",
    "            print(f'Uninstall your current chrome\\'s version this way:' + \"\\n\")\n",
    "    \n",
    "            print(f'sudo apt-get purge --auto-remove google-chrome-stable' + \"\\n\")\n",
    "    \n",
    "            print(f'For the installation you\\'ll need sudo proviligies.' + \"\\n\")\n",
    "    \n",
    "            print(f'sudo apt install ./google-chrome-stable_current_amd64.deb' + \"\\n\")\n",
    "    \n",
    "            print(f'Finally, disable the automatic updates for chrome:' + \"\\n\")\n",
    "    \n",
    "            print(f'sudo apt-mark hold google-chrome-stable' + \"\\n\")\n",
    "    \n",
    "        else:\n",
    "    \n",
    "            print(\"An exception was raised whilst Selenium's webdriver was trying to open google-chrome.\" + \"\\n\")\n",
    "            print(str(e))\n",
    "    \n",
    "        exit(1)\n",
    "    \n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_lemma(frequency_elements: list) -> str or nan:\n",
    "    \n",
    "    \"\"\"\n",
    "    Getting the best lemma for a token from the list of lemmas\n",
    "    available in the field \"Frequency\", scraped from the tokens's URL.\n",
    "    \"\"\"\n",
    "\n",
    "    possible_lemmas = {}\n",
    "\n",
    "    for element in frequency_elements:\n",
    "\n",
    "        lemma = re.search(\"[\\u1F00-\\u1FFF\\u0370-\\u03FF\\ʼ]+\", element.text)\n",
    "\n",
    "        frequency = re.search(\"[0-9]+\", element.text)\n",
    "\n",
    "        # Some frequency elements talks about unranked lemmas.\n",
    "        unranked = re.search(\"unranked\", element.text)\n",
    "\n",
    "        if not unranked:  # If the lemma in the element is ranked,\n",
    "                          # then it is added to the list of possible lemmas.\n",
    "\n",
    "            if lemma and frequency:\n",
    "\n",
    "                possible_lemmas[lemma.group()] = int(frequency.group())\n",
    "\n",
    "        else:  # The lemma in the element is unranked...\n",
    "\n",
    "            if len(frequency_elements) == 1:  # .. and the only one available, the lemma is useful.\n",
    "\n",
    "                best_lemma = lemma.group()\n",
    "\n",
    "    if possible_lemmas:\n",
    "\n",
    "        sorted_lemmas = sorted(possible_lemmas.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "        (best_lemma, _) = sorted_lemmas[0]\n",
    "\n",
    "    return best_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "05npqYnsX7sE"
   },
   "outputs": [],
   "source": [
    "def get_lemma(browser: webdriver, file: str, line: int, token: str, logs: TextIOWrapper) -> str or nan:\n",
    "    \n",
    "    \"\"\"\n",
    "    In this method, given a token, a possible lemma is searched \n",
    "    (scrapped) for it from the url https://logeion.uchicago.edu/morpho/.\n",
    "    \"\"\"\n",
    "\n",
    "    url_base = \"https://logeion.uchicago.edu/morpho/\"\n",
    "\n",
    "    url = url_base + quote(token)\n",
    "\n",
    "    browser.get(url)  # navigate to URL\n",
    "\n",
    "    # The number of \"UL\" html elements to wait for before getting lemmas and its frequencies.\n",
    "    NUM_UL_ELEMENTS = 3\n",
    "\n",
    "    # Setting how the waiting process must be done\n",
    "    wait = WebDriverWait(browser, 10, poll_frequency=1, ignored_exceptions=[TimeoutException, NoSuchElementException])\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    TRACKING_WAITS = 0\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    WAITS = 100  # Number or waiting steps (not seconds)\n",
    "\n",
    "    try:\n",
    "\n",
    "        stable_page = False\n",
    "\n",
    "        while not stable_page:\n",
    "\n",
    "            # Waiting until the Frequency field has some 'p' html elements.\n",
    "\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"p.ng-binding.ng-scope\")))\n",
    "\n",
    "            # -- Getting the HTML elements for the web scraping of lemmas and its frequencies. -- #\n",
    "\n",
    "            md_content_element = browser.find_element(By.CSS_SELECTOR, \"md-content.layout-padding._md\")\n",
    "\n",
    "            div_element = md_content_element.find_element(By.TAG_NAME, \"div\")\n",
    "\n",
    "            ul_elements = div_element.find_elements(By.TAG_NAME, \"ul\")\n",
    "\n",
    "            if not ul_elements:  # For those cases in which there aren't any lemmas and frequencies for the token.\n",
    "\n",
    "                best_lemma = nan\n",
    "\n",
    "                stable_page = True\n",
    "\n",
    "            else:  # Here we have UL html elements to scrap.\n",
    "\n",
    "                # print(f'The length of ul elements: {len(ul_elements)}    token: {token}')\n",
    "\n",
    "                if len(ul_elements) == NUM_UL_ELEMENTS:\n",
    "\n",
    "                    # The second of the ul_elements contains the lemmas and its frequencies.\n",
    "                    frequency_elements = ul_elements[2].find_element(By.TAG_NAME, \"li\").find_elements(By.TAG_NAME, \"p\")\n",
    "\n",
    "                    # Getting the best lemma for a token\n",
    "                    best_lemma = get_best_lemma(frequency_elements)\n",
    "\n",
    "                    stable_page = True\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if TRACKING_WAITS == WAITS:\n",
    "\n",
    "                        logs.write(f'Special URL: Not enough UL html elements in File:: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        best_lemma = nan\n",
    "\n",
    "                        stable_page = True\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        TRACKING_WAITS += 1\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        logs.write(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        logs.write(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        logs.write(f'Getting URL error: An unexpected exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "\n",
    "            browser.find_element(By.XPATH, \"//*[contains(text(), 'Could not find the search term')]\")\n",
    "\n",
    "            lemma = nan\n",
    "\n",
    "        except NoSuchElementException:\n",
    "\n",
    "            try:\n",
    "\n",
    "                browser.find_element(By.XPATH, \"//*[contains(text(), 'Morpho cannot find the form you a searching for')]\")\n",
    "\n",
    "                lemma = nan\n",
    "\n",
    "            except NoSuchElementException:\n",
    "\n",
    "                lemma = best_lemma\n",
    "\n",
    "    finally:\n",
    "\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "k-WyyGXbYCD4"
   },
   "outputs": [],
   "source": [
    "def check_token(token: str) -> bool:\n",
    "    \n",
    "    \"\"\"\n",
    "    A method to warn about possible errors in a token.\n",
    "    \"\"\"\n",
    "\n",
    "    warning = False\n",
    "\n",
    "    invalid_token = re.search(\"[^\\u1F00-\\u1FFF\\u0370-\\u03FF\\.',;·ʼ]\", token)\n",
    "\n",
    "    if invalid_token:\n",
    "\n",
    "        warning = True\n",
    "\n",
    "    return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "id": "frKo7lBzYHVY",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the main folders\n",
    "\n",
    "folders = ['processed', 'warnings', 'logs']\n",
    "\n",
    "root = \"./text/\"\n",
    "\n",
    "corpus = root + \"corpus\"\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "  _path = root + folder\n",
    "  if not path.exists(_path):\n",
    "    os.mkdir(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMhYDHogbU19",
    "outputId": "07865f80-9244-4c81-b43b-c5f610df885d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "-rw-r--r-- 1 jose-lopez jose-lopez 450 ago 23 18:38 aeschylus_i_1.csv\n",
      "-rw-r--r-- 1 jose-lopez jose-lopez 450 sep  5 17:21 aeschylus_i_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Checking if we have the corpus's files ready to go.\n",
    "! ls -l ./text/corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Google Chrome installation....\n",
      "\n",
      "Google Chrome is available: \n",
      "Version: 115.0.5790.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if Google Chrome is available.\n",
    "\n",
    "check_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an instance of the browser's driver in order to consult urls, \n",
    "# deploy the related html pages, and get (scrap) lemmas from them.\n",
    "\n",
    "browser = get_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q7Bpc9Elblj5",
    "outputId": "655e64b1-3fe4-4a86-f557-61d959913939",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmas_scraper:\n",
      "A python script to scrap lemmas from logeion.uchicago.edu/morpho/\n",
      "\n",
      "Getting lemmas for the corpus in ./text/corpus\n",
      "Files: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71a72b692c249848bbae54faf392665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files on process:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2866191a02c45af8fe768acb50f2249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aeschylus_i_1.csv:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d3cd7e4caf4c95b03274a74cb8a8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aeschylus_i_2.csv:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This cell processes the *.csv files located in the text/corpus folder, \n",
    "producing updated versions of them, stored in a folder named\n",
    "\"processed\". Files with warnings and logs are also generated for\n",
    "each one of the *.csv files.\n",
    "\n",
    "A file of the type \"warnings\" informs about possible syntactical errors\n",
    "in tokens in the input files.\n",
    "\n",
    "A \"log\" type file, on the other hand, reports problems found when trying\n",
    "to access a URL, for a given token.\n",
    "\n",
    "The text/processed folder also includes files listing all the new lemmas\n",
    "found for each token in each one of the input files.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Getting an instance of the browser in order to consult urls,\n",
    "# scrap the related html pages, and get (scrap) lemmas from them.\n",
    "browser = get_browser()\n",
    "\n",
    "# ---- Processing the .csv files to add them the token's lemmas ---#\n",
    "\n",
    "processed_files = 0\n",
    "\n",
    "files = [str(x) for x in Path(corpus).glob(\"**/*.csv\")]\n",
    "\n",
    "files_to_process = len(files)\n",
    "\n",
    "warnings_in_file = []\n",
    "\n",
    "print(\"\\n\" + f'Lemmas_scraper:')\n",
    "print(f'A python script to scrap lemmas from logeion.uchicago.edu/morpho/' + \"\\n\")\n",
    "print(f'Getting lemmas for the corpus in ./text/corpus')\n",
    "print(f'Files: {files_to_process}' + \"\\n\")\n",
    "\n",
    "for f in tqdm_notebook(range(files_to_process), desc='Files on process'):\n",
    "\n",
    "    file_name = files[f].split(\"/\")[-1]\n",
    "\n",
    "    file_root_name = \"/\" + file_name.split(\".\")[0]\n",
    "\n",
    "    processed_files += 1\n",
    "\n",
    "    processed_file = root + folders[0] + file_root_name + \"_processed.csv\"\n",
    "\n",
    "    new_lemmas_file = root + folders[0] + file_root_name + \"_new_lemmas.csv\"\n",
    "\n",
    "    warnings_file = root + folders[1] + file_root_name + \"_warnings\" + \".csv\"\n",
    "\n",
    "    logs_file = root + folders[2] + file_root_name + \"_logs\" + \".csv\"\n",
    "\n",
    "    logs = open(\n",
    "        logs_file, 'w', encoding=\"utf8\")\n",
    "\n",
    "    warnings_in_file = []\n",
    "\n",
    "    new_lemmas_in_file = []\n",
    "\n",
    "    input_df = pd.read_csv(files[f])\n",
    "\n",
    "    # A possible lemma is searched for each one of the tokens without one.\n",
    "\n",
    "    for x in tqdm_notebook(range(input_df.index.stop), desc=f'{file_name}'):\n",
    "\n",
    "        token = input_df.loc[x].at[\"token\"]\n",
    "\n",
    "        lemma = input_df.loc[x].at[\"lemma\"]\n",
    "\n",
    "        warning = check_token(token)\n",
    "\n",
    "        if warning:\n",
    "\n",
    "            warnings_in_file.append([x, token])\n",
    "\n",
    "        if lemma is nan:\n",
    "\n",
    "            lemma = get_lemma(browser, files[f], x, token, logs)\n",
    "\n",
    "            # print(f'Token {token}       lemma : {lemma}')\n",
    "\n",
    "            new_lemmas_in_file.append([x, token, lemma])\n",
    "\n",
    "            input_df.loc[x, \"lemma\"] = lemma\n",
    "\n",
    "    input_df.to_csv(processed_file)\n",
    "\n",
    "    # Building the warnings' file, if there are any, for the file on process.\n",
    "\n",
    "    if len(warnings_in_file) != 0:\n",
    "\n",
    "        warnings_df = pd.DataFrame(warnings_in_file, columns=['line', 'token'])\n",
    "\n",
    "        warnings_df.to_csv(warnings_file)\n",
    "\n",
    "    # The new lemmas found are reported.\n",
    "\n",
    "    new_lemmas_in_file_df = pd.DataFrame(new_lemmas_in_file, columns=['line', 'token', 'lemma'])\n",
    "\n",
    "    new_lemmas_in_file_df.to_csv(new_lemmas_file)\n",
    "\n",
    "    logs.close()\n",
    "\n",
    "browser.close()\n",
    "\n",
    "print(f'..... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
