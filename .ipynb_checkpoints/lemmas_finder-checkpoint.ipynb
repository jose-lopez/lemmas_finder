{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Lemmas_finder: A python script to scrap lemmas from:\n",
    "https://logeion.uchicago.edu/morpho/\n",
    "\n",
    "Created on 21 jul. 2023\n",
    "\n",
    "@authors: Jose Lopez, Jacobo Myerston\n",
    "\n",
    "@email: josesmooth@gmail.com\n",
    "\n",
    "@email: jmyerston@gmail.com\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdmAbdbXVG0F",
    "outputId": "a13ff8f7-dd43-4f7b-a43a-82868bf07027"
   },
   "outputs": [],
   "source": [
    "! pip install webdriver-manager\n",
    "! pip install selenium\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BduH8VVtXxf4"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from urllib.parse import quote\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy.core.numeric import nan\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_browser():\n",
    "\n",
    "    print(f'Checking Google Chrome installation....' + \"\\n\")\n",
    "\n",
    "    with os.popen(\"google-chrome --version\") as f:\n",
    "        browser = f.readlines()\n",
    "\n",
    "    if len(browser):\n",
    "\n",
    "        print(f'Google Chrome version: {browser[0]}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f'... Installing Google Chrome' + \"\\n\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(os.popen('wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb').read())\n",
    "            print(os.popen('apt install ./google-chrome-stable_current_amd64.deb').read())\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"An exception was raised whilst the installation of google-chrome was going on.\")\n",
    "            print(e)\n",
    "\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kcwArXWX2AB"
   },
   "outputs": [],
   "source": [
    "def get_browser():\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    options.add_argument(\"--headless=new\")\n",
    "\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "    options.add_argument(\"--ignore-certificate-errors\")\n",
    "\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "\n",
    "    options.add_argument(\"--no-default-browser-check\")\n",
    "\n",
    "    options.add_argument(\"--no-first-run\")\n",
    "\n",
    "    options.add_argument(\"--no-proxy-server\")\n",
    "\n",
    "    options.add_argument(\"--disable-blink-features=AutomationController\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"An exception was raised whilst Selenium's webdriver was trying to open google-chrome.\")\n",
    "        print(e)\n",
    "\n",
    "        exit(1)\n",
    "\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best lemma for a token from the list of lemmas\n",
    "# available in field \"Frequency\" scraped from the tokens's URL.\n",
    "\n",
    "def get_best_lemma(frequency_elements: list) -> str:\n",
    "\n",
    "    possible_lemmas = {}\n",
    "\n",
    "    for element in frequency_elements:\n",
    "\n",
    "        lemma = re.search(\"[\\u1F00-\\u1FFF\\u0370-\\u03FF\\Ê¼]+\", element.text)\n",
    "\n",
    "        frequency = re.search(\"[0-9]+\", element.text)\n",
    "\n",
    "        if lemma and frequency:\n",
    "\n",
    "            possible_lemmas[lemma.group()] = int(frequency.group())\n",
    "\n",
    "    if possible_lemmas:\n",
    "\n",
    "        sorted_lemmas = sorted(possible_lemmas.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        (best_lemma, _) = sorted_lemmas[0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        best_lemma = nan\n",
    "\n",
    "    return best_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05npqYnsX7sE"
   },
   "outputs": [],
   "source": [
    "# This is the main method. Given a token, a possible lemma is searched \n",
    "# (scrapped)for it.\n",
    "\n",
    "def get_lemma(browser, file, line, token, logs):\n",
    "\n",
    "    url_base = \"https://logeion.uchicago.edu/morpho/\"\n",
    "\n",
    "    url = url_base + quote(token)\n",
    "\n",
    "    browser.get(url)  # navigate to URL\n",
    "\n",
    "    # The number of \"UL\" html elements to wait for before getting lemmas and its frequencies.\n",
    "    NUM_UL_ELEMENTS = 3\n",
    "\n",
    "    # Setting how the waiting process must be done\n",
    "    wait = WebDriverWait(browser, 20, poll_frequency=1, ignored_exceptions=[TimeoutException, NoSuchElementException])\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    TRACKING_WAITS = 0\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    WAITS = 1000  # Number or waiting steps (not seconds)\n",
    "\n",
    "    try:\n",
    "\n",
    "        stable_page = False\n",
    "\n",
    "        while not stable_page:\n",
    "\n",
    "            # Waiting until the Frequency field has some 'p' html elements\n",
    "\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"p.ng-binding.ng-scope\")))\n",
    "\n",
    "            # -- Getting the HTML elements for the web scraping of lemmas and its frequencies. -- #\n",
    "\n",
    "            md_content_element = browser.find_element(By.CSS_SELECTOR, \"md-content.layout-padding._md\")\n",
    "\n",
    "            div_element = md_content_element.find_element(By.TAG_NAME, \"div\")\n",
    "\n",
    "            ul_elements = div_element.find_elements(By.TAG_NAME, \"ul\")\n",
    "\n",
    "            if not ul_elements:  # For those cases in which there aren't any lemmas and frequencies for the token.\n",
    "\n",
    "                best_lemma = nan\n",
    "\n",
    "                stable_page = True\n",
    "\n",
    "            else:  # Here we have UL html elements to scrap.\n",
    "\n",
    "                # print(f'The length of ul elements: {len(ul_elements)}    token: {token}')\n",
    "\n",
    "                if len(ul_elements) == NUM_UL_ELEMENTS:\n",
    "\n",
    "                    # The second of the ul_elements contains the lemmas and its frequencies.\n",
    "                    frequency_elements = ul_elements[2].find_element(By.TAG_NAME, \"li\").find_elements(By.TAG_NAME, \"p\")\n",
    "\n",
    "                    # Getting the best lemma for a token\n",
    "                    best_lemma = get_best_lemma(frequency_elements)\n",
    "\n",
    "                    stable_page = True\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if TRACKING_WAITS == WAITS:\n",
    "\n",
    "                        print(f'Special URL: Not enough UL html elements in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        logs.write(f'Special URL: Not enough UL html elements in File:: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        best_lemma = nan\n",
    "\n",
    "                        stable_page = True\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        TRACKING_WAITS += 1\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting URL error: A non anticipated exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting URL error: A non anticipated exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "\n",
    "            browser.find_element(By.XPATH, \"//*[contains(text(), 'Could not find the search term')]\")\n",
    "\n",
    "            lemma = nan\n",
    "\n",
    "        except NoSuchElementException:\n",
    "\n",
    "            try:\n",
    "\n",
    "                browser.find_element(By.XPATH, \"//*[contains(text(), 'Morpho cannot find the form you a searching for')]\")\n",
    "\n",
    "                lemma = nan\n",
    "\n",
    "            except NoSuchElementException:\n",
    "\n",
    "                lemma = best_lemma\n",
    "\n",
    "    finally:\n",
    "\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-WyyGXbYCD4"
   },
   "outputs": [],
   "source": [
    "# A method to warn about basic errors in a token.\n",
    "\n",
    "def check_token(token):\n",
    "\n",
    "    warning = False\n",
    "\n",
    "    invalid_token = re.search(\"[^\\u1F00-\\u1FFF\\u0370-\\u03FF\\.',;Â·Ê¼]\", token)\n",
    "\n",
    "    if invalid_token:\n",
    "\n",
    "        warning = True\n",
    "\n",
    "    return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "frKo7lBzYHVY",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the main folders\n",
    "\n",
    "folders = ['processed', 'warnings', 'logs']\n",
    "\n",
    "root = \"./text/\"\n",
    "\n",
    "corpus = root + \"corpus\"\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "  _path = root + folder\n",
    "  if not path.exists(_path):\n",
    "    os.mkdir(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMhYDHogbU19",
    "outputId": "07865f80-9244-4c81-b43b-c5f610df885d"
   },
   "outputs": [],
   "source": [
    "# Checking if we have the corpus's files ready to go.\n",
    "! ls -l ./text/corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if Google Chrome is available or it is installed, otherwise.\n",
    "\n",
    "install_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an instance of the browser in order to consult urls, \n",
    "# scrap the related html pages and get (scrap) lemmas from them.\n",
    "\n",
    "browser = get_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q7Bpc9Elblj5",
    "outputId": "655e64b1-3fe4-4a86-f557-61d959913939",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This cell processes the *.csv files located in the text/corpus folder, \n",
    "producing updated versions of them, stored in a folder named\n",
    "\"processed\". Files with warnings and logs are also generated for\n",
    "each of the *.csv files.\n",
    "\n",
    "A file of the type \"warnings\" informs about possible syntatical errors\n",
    "in tokens in the input files.\n",
    "\n",
    "A \"log\" type file, on the other hand, reports problems found when trying\n",
    "to access a URL, for a given token.\n",
    "\n",
    "The text/processed folder also includes files listing all the new lemmas\n",
    "found for each token in each one of the input files.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "processed_files = 0\n",
    "\n",
    "browser = get_browser()\n",
    "\n",
    "files = [str(x) for x in Path(corpus).glob(\"**/*.csv\")]\n",
    "\n",
    "files_to_process = len(files)\n",
    "\n",
    "warnings_in_file = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    file_name = \"/\" + file.split(\"/\")[-1]\n",
    "\n",
    "    file_root_name = file_name.split(\".\")[0]\n",
    "\n",
    "    processed_files += 1\n",
    "\n",
    "    processed_file = root + folders[0] + file_root_name + \"_processed.csv\"\n",
    "\n",
    "    new_lemmas_file = root + folders[0] + file_root_name + \"_new_lemmas.csv\"\n",
    "\n",
    "    warnings_file = root + folders[1] + file_root_name + \"_warnings\" + \".csv\"\n",
    "\n",
    "    logs_file = root + folders[2] + file_root_name + \"_logs\" + \".csv\"\n",
    "\n",
    "    logs = open(\n",
    "        logs_file, 'w', encoding=\"utf8\")\n",
    "\n",
    "    warnings_in_file = []\n",
    "\n",
    "    new_lemmas_in_file = []\n",
    "\n",
    "    input_df = pd.read_csv(file)\n",
    "\n",
    "    print(f'Getting lemmas for {file} file: {processed_files} | {files_to_process}' + \"\\n\")\n",
    "\n",
    "    for x in input_df.index:\n",
    "\n",
    "        token = input_df.loc[x, \"token\"]\n",
    "\n",
    "        lemma = input_df.loc[x, \"lemma\"]\n",
    "\n",
    "        warning = check_token(token)\n",
    "\n",
    "        if warning:\n",
    "\n",
    "            warnings_in_file.append([x, token])\n",
    "\n",
    "        if lemma is nan:\n",
    "\n",
    "            lemma = get_lemma(browser, file, x, token, logs)\n",
    "\n",
    "            print(f'Token {token}       lemma : {lemma}')\n",
    "\n",
    "            new_lemmas_in_file.append([x, token, lemma])\n",
    "\n",
    "            input_df.loc[x, \"lemma\"] = lemma\n",
    "\n",
    "    input_df.to_csv(processed_file)\n",
    "\n",
    "    # Building the warnings' file, if there are any, for the file on process.\n",
    "\n",
    "    if len(warnings_in_file) != 0:\n",
    "\n",
    "        print(f'Warnings found for {file} file. A report in {warnings_file}')\n",
    "\n",
    "        warnings_df = pd.DataFrame(warnings_in_file, columns=['line', 'token'])\n",
    "\n",
    "        warnings_df.to_csv(warnings_file)\n",
    "\n",
    "    new_lemmas_in_file_df = pd.DataFrame(new_lemmas_in_file, columns=['line', 'token', 'lemma'])\n",
    "\n",
    "    new_lemmas_in_file_df.to_csv(new_lemmas_file)\n",
    "\n",
    "    logs.close()\n",
    "\n",
    "browser.close()\n",
    "\n",
    "print(f'..... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
