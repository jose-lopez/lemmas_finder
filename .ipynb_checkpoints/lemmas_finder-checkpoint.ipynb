{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdmAbdbXVG0F",
    "outputId": "a13ff8f7-dd43-4f7b-a43a-82868bf07027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: requests in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (2023.7.22)\n",
      "Requirement already satisfied: selenium in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: pandas in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install webdriver-manager\n",
    "! pip install selenium\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BduH8VVtXxf4"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from urllib.parse import quote\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy.core.numeric import nan\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_browser():\n",
    "\n",
    "    print(f'Checking Google Chrome installation....' + \"\\n\")\n",
    "\n",
    "    with os.popen(\"google-chrome --version\") as f:\n",
    "        browser = f.readlines()\n",
    "\n",
    "    if len(browser):\n",
    "\n",
    "        print(f'Google Chrome version: {browser[0]}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f'... Installing Google Chrome' + \"\\n\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(os.popen('wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb').read())\n",
    "            print(os.popen('apt install ./google-chrome-stable_current_amd64.deb').read())\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"An exception was raised whilst the installation of google-chrome was going on.\")\n",
    "            print(e)\n",
    "\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7kcwArXWX2AB"
   },
   "outputs": [],
   "source": [
    "def get_browser():\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    options.add_argument(\"--headless=new\")\n",
    "\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "    options.add_argument(\"--ignore-certificate-errors\")\n",
    "\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "\n",
    "    options.add_argument(\"--no-default-browser-check\")\n",
    "\n",
    "    options.add_argument(\"--no-first-run\")\n",
    "\n",
    "    options.add_argument(\"--no-proxy-server\")\n",
    "\n",
    "    options.add_argument(\"--disable-blink-features=AutomationController\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"An exception was raised whilst Selenium's webdriver was trying to open google-chrome.\")\n",
    "        print(e)\n",
    "\n",
    "        exit(1)\n",
    "\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best lemma for a token from the list of lemmas\n",
    "# available in field \"Frequency\" scraped from the tokens's URL.\n",
    "\n",
    "def get_best_lemma(frequency_elements: list) -> str:\n",
    "\n",
    "    possible_lemmas = {}\n",
    "\n",
    "    for element in frequency_elements:\n",
    "\n",
    "        lemma = re.search(\"[\\u1F00-\\u1FFF\\u0370-\\u03FF\\Ê¼]+\", element.text)\n",
    "\n",
    "        frequency = re.search(\"[0-9]+\", element.text)\n",
    "\n",
    "        if lemma and frequency:\n",
    "\n",
    "            possible_lemmas[lemma.group()] = int(frequency.group())\n",
    "\n",
    "    if possible_lemmas:\n",
    "\n",
    "        sorted_lemmas = sorted(possible_lemmas.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        (best_lemma, _) = sorted_lemmas[0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        best_lemma = nan\n",
    "\n",
    "    return best_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "05npqYnsX7sE"
   },
   "outputs": [],
   "source": [
    "# This is the main method. Given a token, a possible lemma is searched \n",
    "# (scrapped)for it.\n",
    "\n",
    "def get_lemma(browser, file, line, token, logs):\n",
    "\n",
    "    url_base = \"https://logeion.uchicago.edu/morpho/\"\n",
    "\n",
    "    url = url_base + quote(token)\n",
    "\n",
    "    browser.get(url)  # navigate to URL\n",
    "\n",
    "    # The number of \"UL\" html elements to wait for before getting lemmas and its frequencies.\n",
    "    NUM_UL_ELEMENTS = 3\n",
    "\n",
    "    # Setting how the waiting process must be done\n",
    "    wait = WebDriverWait(browser, 10, poll_frequency=1, ignored_exceptions=[TimeoutException, NoSuchElementException])\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    TRACKING_WAITS = 0\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    WAITS = 1000  # Number or waiting steps (not seconds)\n",
    "\n",
    "    try:\n",
    "\n",
    "        stable_page = False\n",
    "\n",
    "        while not stable_page:\n",
    "\n",
    "            # Waiting until the Frequency field has some 'p' html elements\n",
    "\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"p.ng-binding.ng-scope\")))\n",
    "\n",
    "            # -- Getting the HTML elements for the web scraping of lemmas and its frequencies. -- #\n",
    "\n",
    "            md_content_element = browser.find_element(By.CSS_SELECTOR, \"md-content.layout-padding._md\")\n",
    "\n",
    "            div_element = md_content_element.find_element(By.TAG_NAME, \"div\")\n",
    "\n",
    "            ul_elements = div_element.find_elements(By.TAG_NAME, \"ul\")\n",
    "\n",
    "            if not ul_elements:  # For those cases in which there aren't any lemmas and frequencies for the token.\n",
    "\n",
    "                best_lemma = nan\n",
    "\n",
    "                stable_page = True\n",
    "\n",
    "            else:  # Here we have UL html elements to scrap.\n",
    "\n",
    "                # print(f'The length of ul elements: {len(ul_elements)}    token: {token}')\n",
    "\n",
    "                if len(ul_elements) == NUM_UL_ELEMENTS:\n",
    "\n",
    "                    # The second of the ul_elements contains the lemmas and its frequencies.\n",
    "                    frequency_elements = ul_elements[2].find_element(By.TAG_NAME, \"li\").find_elements(By.TAG_NAME, \"p\")\n",
    "\n",
    "                    # Getting the best lemma for a token\n",
    "                    best_lemma = get_best_lemma(frequency_elements)\n",
    "\n",
    "                    stable_page = True\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if TRACKING_WAITS == WAITS:\n",
    "\n",
    "                        print(f'Special URL: Not enough UL html elements in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        logs.write(f'Special URL: Not enough UL html elements in File:: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        best_lemma = nan\n",
    "\n",
    "                        stable_page = True\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        TRACKING_WAITS += 1\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting URL error: A non anticipated exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting URL error: A non anticipated exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "\n",
    "            browser.find_element(By.XPATH, \"//*[contains(text(), 'Could not find the search term')]\")\n",
    "\n",
    "            lemma = nan\n",
    "\n",
    "        except NoSuchElementException:\n",
    "\n",
    "            try:\n",
    "\n",
    "                browser.find_element(By.XPATH, \"//*[contains(text(), 'Morpho cannot find the form you a searching for')]\")\n",
    "\n",
    "                lemma = nan\n",
    "\n",
    "            except NoSuchElementException:\n",
    "\n",
    "                lemma = best_lemma\n",
    "\n",
    "    finally:\n",
    "\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "k-WyyGXbYCD4"
   },
   "outputs": [],
   "source": [
    "# A method to warn about basic errors in a token.\n",
    "\n",
    "def check_token(token):\n",
    "\n",
    "    warning = False\n",
    "\n",
    "    invalid_token = re.search(\"[^\\u1F00-\\u1FFF\\u0370-\\u03FF\\.',;Â·Ê¼]\", token)\n",
    "\n",
    "    if invalid_token:\n",
    "\n",
    "        warning = True\n",
    "\n",
    "    return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "id": "frKo7lBzYHVY",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the main folders\n",
    "\n",
    "folders = ['processed', 'warnings', 'logs']\n",
    "\n",
    "root = \"./text/\"\n",
    "\n",
    "corpus = root + \"corpus\"\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "  _path = root + folder\n",
    "  if not path.exists(_path):\n",
    "    os.mkdir(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMhYDHogbU19",
    "outputId": "07865f80-9244-4c81-b43b-c5f610df885d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12572\n",
      "-rw-r--r-- 1 jose-lopez jose-lopez   452366 ago 22 10:35 aeschylus_i.csv\n",
      "-rw-r--r-- 1 jose-lopez jose-lopez 12418445 ago  9 14:27 athenaeus.csv\n"
     ]
    }
   ],
   "source": [
    "# Checking if we have the corpus's files ready to go.\n",
    "! ls -l ./text/corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Google Chrome installation....\n",
      "\n",
      "Google Chrome version: Google Chrome 115.0.5790.98 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if Google Chrome is available or it is installed, otherwise.\n",
    "\n",
    "install_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an instance of the browser in order to consult urls, \n",
    "# scrap the related html pages and get (scrap) lemmas from them.\n",
    "\n",
    "browser = get_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q7Bpc9Elblj5",
    "outputId": "655e64b1-3fe4-4a86-f557-61d959913939",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting lemmas for text/corpus/aeschylus_i.csv file: 1 | 2\n",
      "\n",
      "Token á¼ÏÎ¸Î­Î½ÏÊ¼       lemma : á¼ÏÎ±ÏÎ¯ÏÎºÏ\n",
      "Token ÏÏÎ¿ÏÏÎ¿Î¼Î¯ÏÎ½       lemma : ÏÏÎ¿ÏÏÏÎ¼Î¹Î¿Î½\n",
      "Token Î»ÎµÏÏÎ¿ÏÎ±Î¼Î¬Î¸ÏÎ½       lemma : Î»ÎµÏÏÎ¿ÏÎ¬Î¼Î±Î¸Î¿Ï\n",
      "Token ÎÎ¯Î±Î½       lemma : Îá¿Î¿Ï\n",
      "Token Î»Î¹ÏÎ¿á¿¦ÏÎ±Î¹       lemma : Î»ÎµÎ¯ÏÏ\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÎ¯\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token Ê¼Î¾Ê¼Î¿Î½Î¿ÏÎ±Î¶ÏÎ¼ÎµÎ½Î±Î¹       lemma : nan\n",
      "Token ÎºÏÎ´Î¹ÏÏÊ¼       lemma : ÎºÏÎ´Î¹ÏÏÎ¿Ï\n",
      "Token Îºá¿¦Î¼Ê¼       lemma : Îºá¿¦Î¼Î±\n",
      "Token Î²Î¿á½¸Ï       lemma : Î²Î¿á¿¦Ï\n",
      "Token Îµá½ÏÏÎ¼ÎµÎ½Î¿Î½       lemma : Îµá½ÏÎ¿Î¼Î±Î¹\n",
      "Token ÏÎ¯Î½Ê¼       lemma : ÏÎ¯Î½Ï\n",
      "Token á¼ÏÎ¹ÎºÎ¿Î¯Î¼ÎµÎ¸Î±       lemma : á¼ÏÎ¹ÎºÎ½Î­Î¿Î¼Î±Î¹\n",
      "Token Ïá¿       lemma : Ïá¿\n",
      "Token ÏÏÎ½ÏÎ¿Î½Î´Ê¼       lemma : ÏÏÎ½ÏÎ¿Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token ÏÎ®Î½Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á½ÏÎµÏ       lemma : nan\n",
      "Token ÏÎ¹Î¼Î¬Î¿ÏÊ¼       lemma : ÏÎ¹Î¼ÏÏÏÏ\n",
      "Token á¼¶Î½Î¯Î½       lemma : á¼¶Î½Î¹Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î²Î¿á½¸Ï       lemma : Î²Î¿á¿¦Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á½Î½ÏÊ¼       lemma : á½ÏÏÎµ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Ïá¾¶Ï       lemma : á½Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼ÏÊ¼       lemma : á½ÏÏÎµ\n",
      "Token ÏÎ±Î¹Î´á½¸Ï       lemma : ÏÎ±á¿Ï\n",
      "Token á½¤Î»ÎµÏÎ¿       lemma : á½Î»Î»ÏÎ¼Î¹\n",
      "Token Î´ÏÏÎ¼Î¬ÏÎ¿ÏÎ¿Ï       lemma : Î´ÏÏÎ¼Î®ÏÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token ÏÎ¹Î»ÏÎ´ÏÏ       lemma : nan\n",
      "Token ÏÎ¿Ï       lemma : nan\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token á¼Î½Î¸ÎµÎ¼Î¯Î¶Î¿Î¼Î±Î¹       lemma : á¼Î½Î¸ÎµÎ¼Î¯Î¶Î¿Î¼Î±Î¹\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¸ÎµÎ¿á½¶       lemma : Î¸ÎµÏÏ\n",
      "Token ÏÎ­Î»Î¿Î¹ÏÊ¼       lemma : ÏÎ­Î»Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¿á½Î´Ê¼       lemma : Î¿á½Î´Î­\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼¥Î¼ÎµÎ½Î¿Ï       lemma : á¼§Î¼Î±Î¹\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÎ¯\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼°Î´Î­ÏÎ¸Ï       lemma : á½ÏÎ¬Ï\n",
      "Token ÏÏÎ¸Î¼á½´Î½       lemma : ÏÏÎ¸Î¼Î®Î½\n",
      "Token Î¼á½¸Î½       lemma : Î¼á½¸Î½\n",
      "Token Î¼ÎµÏÎ±Î³Î½Î¿ÏÏ       lemma : Î¼ÎµÏÎ±Î³Î¹Î³Î½ÏÏÎºÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¸ÏÎµÎ¿Î¼Î­Î½Î±       lemma : Î¸ÏÎ­Î¿Î¼Î±Î¹\n",
      "Token Î¸ÏÎµÎ¿Î¼Î­Î½Î·       lemma : Î¸ÏÎ­Î¿Î¼Î±Î¹\n",
      "Token Î¼Îµ       lemma : á¼Î³Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î£Î¹Î´Î¿Î½Î¯Î±       lemma : Î£Î¹Î´ÏÎ½Î¹Î¿Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼ÏÎ¯Î´ÏÎ¿Î¼Ê¼       lemma : á¼ÏÎ¯Î´ÏÎ¿Î¼Î¿Ï\n",
      "Token Îºá¿¦Î¼Ê¼       lemma : Îºá¿¦Î¼Î±\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¼Ê¼       lemma : á¼Î³Ï\n",
      "Token Î¼Î¿Î¹       lemma : á¼Î³Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¼Ê¼       lemma : á¼Î³Ï\n",
      "Token ÏÎ­Î¼Î½Ê¼       lemma : ÏÎµÎ¼Î½ÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Îá¿Î½Î±       lemma : ÎÎµÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÎÎ®Î½       lemma : ÎÎµÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÏÏÏÊ¼       lemma : ÏÏÏÎµ\n",
      "Token Î²Î¿á½¸Ï       lemma : Î²Î¿á¿¦Ï\n",
      "Token ÏÎ±á¿Î´Ê¼       lemma : ÏÎ±á¿Ï\n",
      "Token á¼ÏÎ¹Î¼Î¬ÏÎ±Ï       lemma : á¼ÏÎ¹Î¼Î¬Î¶Ï\n",
      "Token Î±á½       lemma : Î±á½\n",
      "Token ÏÏÏ       lemma : nan\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÎÎ®Î½       lemma : ÎÎµÏÏ\n",
      "Token á¼°á¿¶       lemma : á¼°ÏÏ\n",
      "Token Î´Îµ       lemma : Î´Îµ\n",
      "Token Ïá¼Î¼Ê¼       lemma : á¼Î¼ÏÏ\n",
      "Token Î´ÎµÎ»ÏÎ¿ÏÎ¼Î­Î½Î±Ï       lemma : Î´ÎµÎ»ÏÏÎ¿Î¼Î±Î¹\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token á¼¡Î¼á¾¶Ï       lemma : á¼¡Î¼Îµá¿Ï\n",
      "Token ÏÎµÏÏÏÎ¼Î­Î½Î¿Î¹       lemma : ÏÏÎ½Î¸Î¬Î½Î¿Î¼Î±Î¹\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token ÏÏÎ½Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token á¼±ÎºÎµÏÎ·ÏÎ¯Î±Ï       lemma : á¼±ÎºÎµÏÎ·ÏÎ¯Î±\n",
      "Token á¼Î³Î¬Î»Î¼Î±ÏÊ¼       lemma : á¼Î³Î±Î»Î¼Î±\n",
      "Token Î¶Î±ÏÏÎµá¿Ê¼       lemma : Î¶Î±ÏÏÎµá¿Î¿Ï\n",
      "Token á¼Î¼ÎµÎ¯Î²ÎµÏÎ¸Ê¼       lemma : á¼Î¼ÎµÎ¯Î²Ï\n",
      "Token ÏÎ¬ÏÎ´Ê¼       lemma : á½Î´Îµ\n",
      "Token á¼ÏÎ­ÏÎ¸Ï       lemma : á¼ÏÎ¿Î¼Î±Î¹\n",
      "Token Î¼Î·Î´Ê¼       lemma : Î¼Î·Î´Î­\n",
      "Token ÎºÎ¬ÏÏÊ¼       lemma : ÎºÎ¬ÏÏÎ±\n",
      "Token á¼´Î´Î¿Î¹ÏÎ¿       lemma : á½ÏÎ¬Ï\n",
      "Token Î¸Î­Î»Î¿Î¹Î¼Ê¼       lemma : á¼Î¸Î­Î»Ï\n",
      "Token ÏÏÎ³Î¬Î´Ê¼       lemma : ÏÏÎ³Î¬Ï\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÏ\n",
      "Token ÏÎ¯Î½Ê¼       lemma : ÏÎ¯Î½Ï\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token á½Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token ÏÎ­Î²ÎµÏÎ¸Ê¼       lemma : ÏÎ­Î²Î¿Î¼Î±Î¹\n",
      "Token á¼Î³Î½á½¸Ï       lemma : á¼Î³Î½ÏÏ\n",
      "Token Î³Î­Î½Î¿Î¹ÏÊ¼       lemma : Î³Î¯Î³Î½Î¿Î¼Î±Î¹\n",
      "Token Ïá¼ÏÎ»Î±ÎºÎ®Î¼Î±Î¸Ê¼       lemma : á¼Î¼ÏÎ»Î¬ÎºÎ·Î¼Î±\n",
      "Token ÏÏÎ½Î´Îµ       lemma : á½Î´Îµ\n",
      "Token á½Î¼á¿Î½       lemma : á½Î¼Îµá¿Ï\n",
      "Token ÏÏÎ½Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token á¼ÏÎ³Î¿Î»á½¶Ï       lemma : á¼ÏÎ³Î¿Î»Î¯Ï\n",
      "Token á¼ÏÎ¸á½´Ï       lemma : á¼ÏÎ¸Î®Ï\n",
      "Token Î¿á½Î´Ê¼       lemma : Î¿á½Î´Î­\n",
      "Token ÏÏÎ»Î»Ê¼       lemma : ÏÎ¿Î»ÏÏ\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÎ¹\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token Ïá½²       lemma : ÏÏÏ\n",
      "Token ÏÎ±á¿¦ÏÊ¼       lemma : Î¿á½ÏÎ¿Ï\n",
      "Token Î»Î­Î³Ê¼       lemma : Î»Î­Î³Ï\n",
      "Token á¼Î¼Î¿Î¯       lemma : á¼Î¼ÏÏ\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token Î Î¯Î½Î´Î¿Ï       lemma : Î Î¯Î½Î´Î¿Ï\n",
      "Token ÏÏÎ±Î½Î¸Îµá¿ÏÊ¼       lemma : ÏÏÎ±Î¯Î½Ï\n",
      "Token ÏÎ¿ÏÊ¼       lemma : ÏÎ¿ÏÎµ\n",
      "Token Î·á½ÏÎµÏÊ¼       lemma : Îµá½ÏÎ¯ÏÎºÏ\n",
      "Token Ïá¼ÏÊ¼       lemma : á¼ÏÏ\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î¸Ê¼       lemma : ÏÏ\n",
      "Token ÏÎ±á¿¦ÏÊ¼       lemma : Î¿á½ÏÎ¿Ï\n",
      "Token Î¼ÏÎ¸Îµá¿ÏÎ¸Ê¼       lemma : Î¼ÏÎ¸Î­Î¿Î¼Î±Î¹\n",
      "Token ÎÎ¹Î²ÏÏÏÎ¹ÎºÎ±á¿Ï       lemma : ÎÎ¹Î²ÏÏÏÎ¹ÎºÏÏ\n",
      "Token á¼Î¼ÏÎµÏÎ­ÏÏÎµÏÎ±Î¹       lemma : á¼Î¼ÏÎµÏÎ®Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token á¼ÏÏÎ­Î½ÏÎ½       lemma : á¼ÏÏÎ·Î½\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token ÏÎ±ÏÊ¼       lemma : ÏÎ±ÏÎ¬\n",
      "Token á¼ÏÏÏÎ³ÎµÎ¹ÏÎ¿Î½Î¿ÏÎ¼Î­Î½Î±Ï       lemma : á¼ÏÏÏÎ³ÎµÎ¹ÏÎ¿Î½Î­Î¿Î¼Î±Î¹\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î³Î­Î½ÎµÎ¸Î»Î¿Î½       lemma : Î³Î­Î½ÎµÎ¸Î»Î¿Î½\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Îá¿Î½Î±       lemma : ÎÎµÏÏ\n",
      "Token Î³Ê¼       lemma : Î³Îµ\n",
      "Token Î¸ÎµÏÏ       lemma : Î¸ÎµÏÏ\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÎ¯\n",
      "Token ÏÎ±á¿¦ÏÊ¼       lemma : Î¿á½ÏÎ¿Ï\n",
      "Token Î²Î¿Î       lemma : Î²Î¿á¿¦Ï\n",
      "Token Î½Î¹Î½       lemma : Î½Î¹Î½\n",
      "Token ÏÎ±á¿¦ÏÊ¼       lemma : Î¿á½ÏÎ¿Ï\n",
      "Token á¼Î¼Î¿Î¯       lemma : á¼Î¼ÏÏ\n",
      "Token ÎÎ­Î¼ÏÎ¹Î½       lemma : ÎÎ­Î¼ÏÎ¹Ï\n",
      "Token á¼µÎºÎµÏÎ¿       lemma : á¼±ÎºÎ½Î­Î¿Î¼Î±Î¹\n",
      "Token Î³Ê¼       lemma : Î³Îµ\n",
      "Token Îá¿Î¿Ï       lemma : Îá¿Î¿Ï\n",
      "Token ÏÎ¯Î½Ê¼       lemma : ÏÎ¯Î½Ï\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÎ¹\n",
      "Token ÏÎ¿á¿¦Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token ÏÎ¿á¿¦ÏÏ       lemma : Î¿á½ÏÎ¿Ï\n",
      "Token Î¼Î¿Î¹       lemma : á¼Î³Ï\n",
      "Token ÏÎ¿á½Î½Î¿Î¼Ê¼       lemma : á½Î½Î¿Î¼Î±\n",
      "Token á¼Î¼á½¸Î½       lemma : á¼Î¼ÏÏ\n",
      "Token Î¼Î¿Î¹       lemma : á¼Î³Ï\n",
      "Token ÏÎ¯Ï       lemma : ÏÎ¯Ï\n",
      "Token Î±á¼°ÏÎ»Ê¼       lemma : Î±á¼°ÏÎ»Î¿Ï\n",
      "Token ÏÎ®Î½Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token Î¼ÎµÏÎ±ÏÏÎ¿Î¹Î¿á¿¦ÏÎ±Î½       lemma : Î¼ÎµÏÎ±ÏÏÎ¿Î¹Î­Ï\n",
      "Token Ïá¿¶Î½Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token Î»ÎµÏÎºÎ¿ÏÏÎµÏÎµá¿Ï       lemma : Î»ÎµÏÎºÎ¿ÏÏÎµÏÎ®Ï\n",
      "Token Î³Î­Î½ÏÎ¼Î±Î¹       lemma : Î³Î¯Î³Î½Î¿Î¼Î±Î¹\n",
      "Token á½ Î½Î¿á¿ÏÎ¿       lemma : á½ Î½Î­Î¿Î¼Î±Î¹\n",
      "Token ÎºÎµÎºÏÎ·Î¼Î­Î½Î¿ÏÏ       lemma : ÎºÏÎ¬Î¿Î¼Î±Î¹\n",
      "Token Î³Ê¼       lemma : Î³Îµ\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token ÏÎ±Î¹Ïá½¶Î½       lemma : ÏÎ±á¿Ï\n",
      "Token Î³Ê¼       lemma : Î³Îµ\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token Î³Ê¼       lemma : Î³Îµ\n",
      "Token ÎºÎ¿Î¹Î½ÏÎ½á½¸Ï       lemma : ÎºÎ¿Î¹Î½ÏÎ½ÏÏ\n",
      "Token á½§Î´Ê¼       lemma : á½§Î´Îµ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¼Î¿Ï       lemma : á¼Î³Ï\n",
      "Token Î¼Îµ       lemma : á¼Î³Ï\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token á¼µÎ½Ê¼       lemma : á¼µÎ½Î±\n",
      "Token Î¼Î­Î¼Ï       lemma : nan\n",
      "Token ÎºÎµ       lemma : á¼Î½\n",
      "Token Î½ÎµÏÎ¿Î½Î¸Ê¼       lemma : Î½ÎµÏÏ\n",
      "Token ÏÎ¿á¿¦ÏÊ¼       lemma : Î¿á½ÏÎ¿Ï\n",
      "Token Î¼Î·Î´Ê¼       lemma : Î¼Î·Î´Î­\n",
      "Token Î³Î­Î½Î·ÏÎ±Î¹       lemma : Î³Î¯Î³Î½Î¿Î¼Î±Î¹\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼´Î´Î¿Î¹ÏÎ¿       lemma : á½ÏÎ¬Ï\n",
      "Token Ïá½º       lemma : ÏÏ\n",
      "Token á½ÏÎ¹Î³ÏÎ½Î¿Ï       lemma : á½ÏÎ¯Î³Î¿Î½Î¿Ï\n",
      "Token Î±á¼°Î´ÏÎ¼ÎµÎ½Î¿Ï       lemma : Î±á¼°Î´Î­Î¿Î¼Î±Î¹\n",
      "Token á¼±ÎµÏÎ¿Î´ÏÎºÎ±       lemma : á¼±ÎµÏÎ¿Î´ÏÎºÎ¿Ï\n",
      "Token Î»Î®Î¼Î±ÏÊ¼       lemma : Î»á¿Î¼Î±\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÏ\n",
      "Token ÎºÎ¬Î¸Î·ÏÎ¸Îµ       lemma : ÎºÎ±Î¸Î¯Î·Î¼Î¹\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token ÎºÏÎ±Î¯Î½Î¿Î¹Î¼Ê¼       lemma : ÎºÏÎ±Î¯Î½Ï\n",
      "Token á½ÏÏÏÏÎµÏÎ¹Î½       lemma : á½ÏÏÏÏÎµÏÎ¹Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¿á½Î´Ê¼       lemma : Î¿á½Î´Î­\n",
      "Token ÏÏÎ´Ê¼       lemma : á½Î´Îµ\n",
      "Token Î¼Ê¼       lemma : á¼Î³Ï\n",
      "Token ÏÏÎ­Î½Î±Ï       lemma : ÏÏÎ®Î½\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÏÎºÎ¿Ïá½¸Î½       lemma : ÏÎºÎ¿ÏÏÏ\n",
      "Token ÏÏÎ¿ÏÎ®Î¼ÎµÎ½Î¿Î¹       lemma : ÏÏÏÏÎ·Î¼Î±Î¹\n",
      "Token ÏÎµ       lemma : ÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÏÎ¿ÏÊ¼       lemma : ÏÎ¿ÏÎµ\n",
      "Token á¼ÏÏÎ­Î½ÏÎ½       lemma : á¼ÏÏÎ·Î½\n",
      "Token á¼Î»ÏÎ¼ÎµÎ½Î¿Ï       lemma : Î±á¼±ÏÎ­Ï\n",
      "Token Î¼Ê¼       lemma : á¼Î³Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¼ÎµÏÎ±Î»       lemma : nan\n",
      "Token Î³Îµá¿Ï       lemma : nan\n",
      "Token Î¼Î·Î´Ê¼       lemma : Î¼Î·Î´Î­\n",
      "Token Î±á½ÏÎ¿á¿ÏÎ¯       lemma : Î±á½ÏÏÏ\n",
      "Token Î¸Ê¼       lemma : ÏÏ\n",
      "Token á¼¡Î¼á¿Î½       lemma : á¼¡Î¼Îµá¿Ï\n",
      "Token Î¼Î®ÏÊ¼       lemma : Î¼Î®ÏÎµ\n",
      "Token á½§Î´Ê¼       lemma : á½§Î´Îµ\n",
      "Token Î¸Îµá½¸Î½       lemma : Î¸ÎµÏÏ\n",
      "Token Î¿á½Î´Ê¼       lemma : Î¿á½Î´Î­\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î¼Ê¼       lemma : á¼Î³Ï\n",
      "Token á¿¥ÏÏÎ¹Î±       lemma : nan\n",
      "Token ÏÎ¸Îµá¿ÏÎ±Î½       lemma : nan\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÏÎ±Î¹Ïá½¶       lemma : ÏÎ±á¿Ï\n",
      "Token á½ÏÏÏÎµÏÊ¼       lemma : á½ÏÏÏÎµÏÎ¿Ï\n",
      "Token ÏÏÎ¬ÏÎ±Î¹       lemma : ÏÏÎ¬Î¶Ï\n",
      "Token Ïá¾¶ÏÊ¼       lemma : Ïá¾¶Ï\n",
      "Token á¼ÏÏÊ¼       lemma : á¼ÏÏÎµ\n",
      "Token Î½Î±ÏÏÎ¹ÎºÎ±á¿ÏÎ¹Î½       lemma : Î½Î±ÏÏÎ¹ÎºÏÏ\n",
      "Token Î¼Î­Î³Ê¼       lemma : Î¼Î­Î³Î±Ï\n",
      "Token Î³Î­Î½Î¿Î¹ÏÊ¼       lemma : Î³Î¯Î³Î½Î¿Î¼Î±Î¹\n",
      "Token Î³Î­Î½Î¿Î¹ÏÎ¿       lemma : Î³Î¯Î³Î½Î¿Î¼Î±Î¹\n",
      "Token Î³Î­Î½Î¿Î¹ÏÎ¿       lemma : Î³Î¯Î³Î½Î¿Î¼Î±Î¹\n",
      "Token Î¼Îµ       lemma : á¼Î³Ï\n",
      "Token ÏÎ¬ÏÊ¼       lemma : ÏÎ¬ÏÎ±\n",
      "Token ÏÎ¯Î½Ê¼       lemma : ÏÎ¯Î½Ï\n",
      "Token Î³Î·ÏÏÎ¸Îµá¿ÏÊ¼       lemma : Î³Î·ÏÏÏ\n",
      "Token á¼Ïá¿       lemma : Îµá¼°ÏÎ¯Î·Î¼Î¹\n",
      "Token ÏÎ¹ÏÏá½¸Î½       lemma : ÏÎ¹ÏÏÏÎ½\n",
      "Token Ïá¿·Î´Ê¼       lemma : á½Î´Îµ\n",
      "Token ÏÎ¿Î¹       lemma : ÏÏ\n",
      "Token Î±á¼°Î½Î¹Î³Î¼Î±Ïá¿¶Î´ÎµÏ       lemma : Î±á¼°Î½Î¹Î³Î¼Î±ÏÏÎ´Î·Ï\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token ÏÎ¬ÏÎ¹ÏÏÊ¼       lemma : ÏÎ±ÏÏÏ\n",
      "Token Î¼Î¬Î»Ê¼       lemma : Î¼Î¬Î»Î±\n",
      "Token ÏÏÎ´Ê¼       lemma : á½Î´Îµ\n",
      "Token á½Î¼á¿Î½       lemma : á½Î¼Îµá¿Ï\n",
      "Token Î¼á½´       lemma : Î¼Î®\n",
      "Token ÏÏÎ´Ê¼       lemma : á½Î´Îµ\n",
      "Token ÏÎ±Î¹Ïá½¶Î½       lemma : ÏÎ±á¿Ï\n",
      "Token Î±á¼¶ÏÊ¼       lemma : Î±á¼¶ÏÎ±\n",
      "Token á¼ÏÊ¼       lemma : á¼ÏÎ¯\n",
      "Token Î¼Î·Î´Ê¼       lemma : Î¼Î·Î´Î­\n",
      "Token á¼Î¼Î¿á¿¦       lemma : á¼Î¼Î­Ï\n",
      "Token á¼¥ÏÏÎ¿ÏÎ¹Î½       lemma : á¼¥ÏÏÏÎ½\n",
      "Token á¼¡Î¼á¿Î½       lemma : á¼¡Î¼Îµá¿Ï\n",
      "Token ÏÊ¼       lemma : ÏÏ\n",
      "Token Î´Î¹Ê¼       lemma : Î´Î¹Ï\n",
      "Token ÏÏÎµÎ¯ÏÎ¿Î¹ÏÊ¼       lemma : ÏÏÎµÎ¯ÏÏ\n",
      "Token á¼¡Î³Îµá¿ÏÎ¸Îµ       lemma : á¼¡Î³Î­Î¿Î¼Î±Î¹\n",
      "Token ÏÏÎµá½¼Î½       lemma : ÏÏÎµÏÎ½\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token á¼Î¼Î¿Î¯       lemma : á¼Î¼ÏÏ\n",
      "Token ÎºÎ±ÏÊ¼       lemma : ÎºÎ±ÏÎ¬\n",
      "Token Î¼Îµ       lemma : á¼Î³Ï\n",
      "Token ÏÊ¼       lemma : ÏÏÏ\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token Î´ÏÎ±ÎºÏÎ½ÏÏÎ½       lemma : Î´Î­ÏÎºÎ¿Î¼Î±Î¹\n",
      "Token á¼ÏÎ¸Î¯Î¿ÏÎ¹Î½       lemma : á¼ÏÎ¸ÏÏÏ\n",
      "Token Î³Ê¼       lemma : Î³Îµ\n",
      "Token á¼Î»Î»Ê¼       lemma : á¼Î»Î»Î¬\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token Ïá½¸Î½       lemma : ÏÏÏ\n",
      "Token Î¸ÎµÎ¿á½ºÏ       lemma : Î¸ÎµÏÏ\n",
      "Token Î»Î¹ÏÎ±á¿Ï       lemma : Î»Î¹ÏÎ®\n",
      "Token ÏÎ±ÏÎ±Î¹ÏÎ¿á¿¦       lemma : ÏÎ±ÏÎ±Î¹ÏÎ­Î¿Î¼Î±Î¹\n",
      "Token ÏÊ¼       lemma : ÏÏÏ\n",
      "Token á¼Î³á½¼       lemma : á¼Î³Ï\n",
      "Token á¼ÏÎ¿Î¹ÏÎ¿       lemma : á¼ÏÎ¿Î¼Î±Î¹\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Îµá½ÏÏÎ¿Î½Ê¼       lemma : Îµá½ÏÏÏÎ½\n",
      "Token Îµá½ÏÏÎ¼ÎµÎ¸Ê¼       lemma : Îµá½ÏÎ¿Î¼Î±Î¹\n",
      "Token Ïá¾¶ÏÎ´Ê¼       lemma : á½Î´Îµ\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î´Î¹Î±ÏÎ­Î¼       lemma : nan\n",
      "Token Î½Î¿ÏÏÎ±       lemma : nan\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼ÏÎ¯Î´Î¿Ï       lemma : á¼ÏÎ¯Ï\n",
      "Token Î´Î¹Ê¼       lemma : Î´Î¹Ï\n",
      "Token ÎÎ¹Î»Î¯ÎºÏÎ½       lemma : ÎÎ¯Î»Î¹Î¾\n",
      "Token Î Î±Î¼ÏÏÎ»ÏÎ½       lemma : Î Î¬Î¼ÏÏÎ»Î¿Ï\n",
      "Token Î´Î¹Î¿ÏÎ½ÏÎ¼Î­Î½Î±       lemma : Î´Î¹ÏÏÎ½ÏÎ¼Î±Î¹\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token ÏÎ¹Î½Î¿ÏÎ¼Î­Î½Î±       lemma : ÏÎ¯Î½Î¿Î¼Î±Î¹\n",
      "Token Î¼Î±Î¹Î½Î¿Î¼Î­Î½Î±       lemma : Î¼Î±Î¯Î½Î¿Î¼Î±Î¹\n",
      "Token á¼ÏÎ¯       lemma : nan\n",
      "Token Î¼Î¿Î¹Ï       lemma : nan\n",
      "Token ÎºÎµÎ½ÏÏÎ¿Î´Î±       lemma : nan\n",
      "Token Î»Î®ÏÎ¹ÏÎ¹       lemma : nan\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token Ïá½°Î½       lemma : á½Ï\n",
      "Token Î¸Î­Î»       lemma : nan\n",
      "Token Î¾Î±Ï       lemma : nan\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token Î´Î¹Ê¼       lemma : Î´Î¹Ï\n",
      "Token ÎºÏÎ­ÏÎ½       lemma : ÎºÏÎµÎ¯ÏÎ½\n",
      "Token á¼ÏÎ¿       lemma : nan\n",
      "Token Î³ÎµÎ¯Î½Î±ÏÎ¿       lemma : Î³ÎµÎ¯Î½Î¿Î¼Î±Î¹\n",
      "Token ÏÎ±á¿Î´Ê¼       lemma : ÏÎ±á¿Ï\n",
      "Token Î§Î¿ÏÏÏ       lemma : ÏÎ¿ÏÏÏ\n",
      "Token á¼­       lemma : á½Ï\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This cell processes the *.csv files located in the text/corpus folder, \n",
    "producing updated versions of them, stored in a folder named\n",
    "\"processed\". Files with warnings and logs are also generated for\n",
    "each of the *.csv files.\n",
    "\n",
    "A file of the type \"warnings\" informs about possible syntatical errors\n",
    "in tokens in the input files.\n",
    "\n",
    "A \"log\" type file, on the other hand, reports problems found when trying\n",
    "to access a URL, for a given token.\n",
    "\n",
    "The text/processed folder also includes files listing all the new lemmas\n",
    "found for each token in each one of the input files.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "processed_files = 0\n",
    "\n",
    "browser = get_browser()\n",
    "\n",
    "files = [str(x) for x in Path(corpus).glob(\"**/*.csv\")]\n",
    "\n",
    "files_to_process = len(files)\n",
    "\n",
    "warnings_in_file = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    file_name = \"/\" + file.split(\"/\")[-1]\n",
    "\n",
    "    file_root_name = file_name.split(\".\")[0]\n",
    "\n",
    "    processed_files += 1\n",
    "\n",
    "    processed_file = root + folders[0] + file_root_name + \"_processed.csv\"\n",
    "\n",
    "    new_lemmas_file = root + folders[0] + file_root_name + \"_new_lemmas.csv\"\n",
    "\n",
    "    warnings_file = root + folders[1] + file_root_name + \"_warnings\" + \".csv\"\n",
    "\n",
    "    logs_file = root + folders[2] + file_root_name + \"_logs\" + \".csv\"\n",
    "\n",
    "    logs = open(\n",
    "        logs_file, 'w', encoding=\"utf8\")\n",
    "\n",
    "    warnings_in_file = []\n",
    "\n",
    "    new_lemmas_in_file = []\n",
    "\n",
    "    input_df = pd.read_csv(file)\n",
    "\n",
    "    print(f'Getting lemmas for {file} file: {processed_files} | {files_to_process}' + \"\\n\")\n",
    "\n",
    "    for x in input_df.index:\n",
    "\n",
    "        token = input_df.loc[x, \"token\"]\n",
    "\n",
    "        lemma = input_df.loc[x, \"lemma\"]\n",
    "\n",
    "        warning = check_token(token)\n",
    "\n",
    "        if warning:\n",
    "\n",
    "            warnings_in_file.append([x, token])\n",
    "\n",
    "        if lemma is nan:\n",
    "\n",
    "            lemma = get_lemma(browser, file, x, token, logs)\n",
    "\n",
    "            print(f'Token {token}       lemma : {lemma}')\n",
    "\n",
    "            new_lemmas_in_file.append([x, token, lemma])\n",
    "\n",
    "            input_df.loc[x, \"lemma\"] = lemma\n",
    "\n",
    "    input_df.to_csv(processed_file)\n",
    "\n",
    "    # Building the warnings' file, if there are any, for the file on process.\n",
    "\n",
    "    if len(warnings_in_file) != 0:\n",
    "\n",
    "        print(f'Warnings found for {file} file. A report in {warnings_file}')\n",
    "\n",
    "        warnings_df = pd.DataFrame(warnings_in_file, columns=['line', 'token'])\n",
    "\n",
    "        warnings_df.to_csv(warnings_file)\n",
    "\n",
    "    new_lemmas_in_file_df = pd.DataFrame(new_lemmas_in_file, columns=['line', 'token', 'lemma'])\n",
    "\n",
    "    new_lemmas_in_file_df.to_csv(new_lemmas_file)\n",
    "\n",
    "    logs.close()\n",
    "\n",
    "browser.close()\n",
    "\n",
    "print(f'..... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
