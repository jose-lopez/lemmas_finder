{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Lemmas_finder: A python script to scrap lemmas from:\n",
    "https://logeion.uchicago.edu/morpho/\n",
    "\n",
    "Created on 21 jul. 2023\n",
    "\n",
    "@authors: Jose Lopez, Jacobo Myerston\n",
    "\n",
    "@email: josesmooth@gmail.com\n",
    "\n",
    "@email: jmyerston@gmail.com\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdmAbdbXVG0F",
    "outputId": "a13ff8f7-dd43-4f7b-a43a-82868bf07027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: requests in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from requests->webdriver-manager) (2023.7.22)\n",
      "Requirement already satisfied: selenium in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: pandas in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jose-lopez/anaconda3/envs/spacy/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install webdriver-manager\n",
    "! pip install selenium\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BduH8VVtXxf4"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from urllib.parse import quote\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy.core.numeric import nan\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_browser():\n",
    "\n",
    "    print(f'Checking Google Chrome installation....' + \"\\n\")\n",
    "\n",
    "    with os.popen(\"google-chrome --version\") as f:\n",
    "        browser = f.readlines()\n",
    "\n",
    "    if len(browser):\n",
    "\n",
    "        print(f'Google Chrome version: {browser[0]}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f'... Installing Google Chrome' + \"\\n\")\n",
    "\n",
    "        try:\n",
    "            print(os.popen('wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb').read())\n",
    "            print(os.popen('apt install ./google-chrome-stable_current_amd64.deb').read())\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"An exception was raised whilst the installation of google-chrome was going on.\")\n",
    "            print(e)\n",
    "\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7kcwArXWX2AB"
   },
   "outputs": [],
   "source": [
    "def get_browser():\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    options.add_argument(\"--headless=new\")\n",
    "\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "    options.add_argument(\"--ignore-certificate-errors\")\n",
    "\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "\n",
    "    options.add_argument(\"--no-default-browser-check\")\n",
    "\n",
    "    options.add_argument(\"--no-first-run\")\n",
    "\n",
    "    options.add_argument(\"--no-proxy-server\")\n",
    "\n",
    "    options.add_argument(\"--disable-blink-features=AutomationController\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"An exception was raised whilst Selenium's webdriver was trying to open google-chrome.\")\n",
    "        print(e)\n",
    "\n",
    "        exit(1)\n",
    "\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best lemma for a token from the list of lemmas\n",
    "# available in field \"Frequency\", scraped from the tokens's URL.\n",
    "\n",
    "def get_best_lemma(frequency_elements: list) -> str:\n",
    "\n",
    "    possible_lemmas = {}\n",
    "\n",
    "    for element in frequency_elements:\n",
    "\n",
    "        # Some frequency elements talks about unranked lemmas, those must be kept out.\n",
    "        unranked = re.search(\"unranked\", element.text)\n",
    "\n",
    "        if not unranked:  # If the element is ranked,then it is added to the list of possible lemmas.\n",
    "\n",
    "            lemma = re.search(\"[\\u1F00-\\u1FFF\\u0370-\\u03FF\\ʼ]+\", element.text)\n",
    "\n",
    "            frequency = re.search(\"[0-9]+\", element.text)\n",
    "\n",
    "            if lemma and frequency:\n",
    "\n",
    "                possible_lemmas[lemma.group()] = int(frequency.group())\n",
    "\n",
    "    if possible_lemmas:\n",
    "\n",
    "        sorted_lemmas = sorted(possible_lemmas.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "        (best_lemma, _) = sorted_lemmas[0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        best_lemma = nan\n",
    "\n",
    "    return best_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "05npqYnsX7sE"
   },
   "outputs": [],
   "source": [
    "# This is the main method. Given a token, a possible lemma is searched \n",
    "# (scrapped)for it.\n",
    "\n",
    "def get_lemma(browser, file, line, token, logs):\n",
    "\n",
    "    url_base = \"https://logeion.uchicago.edu/morpho/\"\n",
    "\n",
    "    url = url_base + quote(token)\n",
    "\n",
    "    browser.get(url)  # navigate to URL\n",
    "\n",
    "    # The number of \"UL\" html elements to wait for before getting lemmas and its frequencies.\n",
    "    NUM_UL_ELEMENTS = 3\n",
    "\n",
    "    # Setting how the waiting process must be done\n",
    "    wait = WebDriverWait(browser, 20, poll_frequency=1, ignored_exceptions=[TimeoutException, NoSuchElementException])\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    TRACKING_WAITS = 0\n",
    "\n",
    "    # For those unexpected or unknown html pages. This ensure we will know special tokens to debug.\n",
    "    WAITS = 1000  # Number or waiting steps (not seconds)\n",
    "\n",
    "    try:\n",
    "\n",
    "        stable_page = False\n",
    "\n",
    "        while not stable_page:\n",
    "\n",
    "            # Waiting until the Frequency field has some 'p' html elements.\n",
    "\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"p.ng-binding.ng-scope\")))\n",
    "\n",
    "            # -- Getting the HTML elements for the web scraping of lemmas and its frequencies. -- #\n",
    "\n",
    "            md_content_element = browser.find_element(By.CSS_SELECTOR, \"md-content.layout-padding._md\")\n",
    "\n",
    "            div_element = md_content_element.find_element(By.TAG_NAME, \"div\")\n",
    "\n",
    "            ul_elements = div_element.find_elements(By.TAG_NAME, \"ul\")\n",
    "\n",
    "            if not ul_elements:  # For those cases in which there aren't any lemmas and frequencies for the token.\n",
    "\n",
    "                best_lemma = nan\n",
    "\n",
    "                stable_page = True\n",
    "\n",
    "            else:  # Here we have UL html elements to scrap.\n",
    "\n",
    "                # print(f'The length of ul elements: {len(ul_elements)}    token: {token}')\n",
    "\n",
    "                if len(ul_elements) == NUM_UL_ELEMENTS:\n",
    "\n",
    "                    # The second of the ul_elements contains the lemmas and its frequencies.\n",
    "                    frequency_elements = ul_elements[2].find_element(By.TAG_NAME, \"li\").find_elements(By.TAG_NAME, \"p\")\n",
    "\n",
    "                    # Getting the best lemma for a token\n",
    "                    best_lemma = get_best_lemma(frequency_elements)\n",
    "\n",
    "                    stable_page = True\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if TRACKING_WAITS == WAITS:\n",
    "\n",
    "                        print(f'Special URL: Not enough UL html elements in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        logs.write(f'Special URL: Not enough UL html elements in File:: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "                        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "                        best_lemma = nan\n",
    "\n",
    "                        stable_page = True\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        TRACKING_WAITS += 1\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting not Frequencies error: An exception of type NoSuchElementException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting URL error: An exception of type TimeoutException in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        lemma = nan\n",
    "\n",
    "        print(f'Getting URL error: A non anticipated exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        print(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "        logs.write(f'Getting URL error: A non anticipated exception in File: {file} at line: {line}, token {token}' + \"\\n\")\n",
    "        logs.write(f'URL: {url}' + \"\\n\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "\n",
    "            browser.find_element(By.XPATH, \"//*[contains(text(), 'Could not find the search term')]\")\n",
    "\n",
    "            lemma = nan\n",
    "\n",
    "        except NoSuchElementException:\n",
    "\n",
    "            try:\n",
    "\n",
    "                browser.find_element(By.XPATH, \"//*[contains(text(), 'Morpho cannot find the form you a searching for')]\")\n",
    "\n",
    "                lemma = nan\n",
    "\n",
    "            except NoSuchElementException:\n",
    "\n",
    "                lemma = best_lemma\n",
    "\n",
    "    finally:\n",
    "\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "k-WyyGXbYCD4"
   },
   "outputs": [],
   "source": [
    "# A method to warn about basic errors in a token.\n",
    "\n",
    "def check_token(token):\n",
    "\n",
    "    warning = False\n",
    "\n",
    "    invalid_token = re.search(\"[^\\u1F00-\\u1FFF\\u0370-\\u03FF\\.',;·ʼ]\", token)\n",
    "\n",
    "    if invalid_token:\n",
    "\n",
    "        warning = True\n",
    "\n",
    "    return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "id": "frKo7lBzYHVY",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the main folders\n",
    "\n",
    "folders = ['processed', 'warnings', 'logs']\n",
    "\n",
    "root = \"./text/\"\n",
    "\n",
    "corpus = root + \"corpus\"\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "  _path = root + folder\n",
    "  if not path.exists(_path):\n",
    "    os.mkdir(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMhYDHogbU19",
    "outputId": "07865f80-9244-4c81-b43b-c5f610df885d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2880\n",
      "-rw-r--r-- 1 jose-lopez jose-lopez  452366 ago 22 10:35 aeschylus_i.csv\n",
      "-rw-r--r-- 1 jose-lopez jose-lopez 2494194 ago  9 14:27 xenophon_ii.csv\n"
     ]
    }
   ],
   "source": [
    "# Checking if we have the corpus's files ready to go.\n",
    "! ls -l ./text/corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Google Chrome installation....\n",
      "\n",
      "Google Chrome version: Google Chrome 115.0.5790.98 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if Google Chrome is available or it is installed, otherwise.\n",
    "\n",
    "install_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an instance of the browser in order to consult urls, \n",
    "# scrap the related html pages and get (scrap) lemmas from them.\n",
    "\n",
    "browser = get_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q7Bpc9Elblj5",
    "outputId": "655e64b1-3fe4-4a86-f557-61d959913939",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting lemmas for text/corpus/aeschylus_i.csv file: 1 | 2\n",
      "\n",
      "Token ἀρθέντʼ       lemma : αἴρω\n",
      "Token προστομίων       lemma : nan\n",
      "Token λεπτοψαμάθων       lemma : nan\n",
      "Token Δίαν       lemma : nan\n",
      "Token λιποῦσαι       lemma : λείπω\n",
      "Token ἐφʼ       lemma : ἐπί\n",
      "Token ἀλλʼ       lemma : ἀλλά\n",
      "Token ʼξʼονοταζόμεναι       lemma : nan\n",
      "Token κύδιστʼ       lemma : nan\n",
      "Token κῦμʼ       lemma : κῦμα\n",
      "Token βοὸς       lemma : βοῦς\n",
      "Token εὐχόμενον       lemma : εὔχομαι\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This cell processes the *.csv files located in the text/corpus folder, \n",
    "producing updated versions of them, stored in a folder named\n",
    "\"processed\". Files with warnings and logs are also generated for\n",
    "each one of the *.csv files.\n",
    "\n",
    "A file of the type \"warnings\" informs about possible syntatical errors\n",
    "in tokens in the input files.\n",
    "\n",
    "A \"log\" type file, on the other hand, reports problems found when trying\n",
    "to access a URL, for a given token.\n",
    "\n",
    "The text/processed folder also includes files listing all the new lemmas\n",
    "found for each token in each one of the input files.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "processed_files = 0\n",
    "\n",
    "browser = get_browser()\n",
    "\n",
    "files = [str(x) for x in Path(corpus).glob(\"**/*.csv\")]\n",
    "\n",
    "files_to_process = len(files)\n",
    "\n",
    "warnings_in_file = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    file_name = \"/\" + file.split(\"/\")[-1]\n",
    "\n",
    "    file_root_name = file_name.split(\".\")[0]\n",
    "\n",
    "    processed_files += 1\n",
    "\n",
    "    processed_file = root + folders[0] + file_root_name + \"_processed.csv\"\n",
    "\n",
    "    new_lemmas_file = root + folders[0] + file_root_name + \"_new_lemmas.csv\"\n",
    "\n",
    "    warnings_file = root + folders[1] + file_root_name + \"_warnings\" + \".csv\"\n",
    "\n",
    "    logs_file = root + folders[2] + file_root_name + \"_logs\" + \".csv\"\n",
    "\n",
    "    logs = open(\n",
    "        logs_file, 'w', encoding=\"utf8\")\n",
    "\n",
    "    warnings_in_file = []\n",
    "\n",
    "    new_lemmas_in_file = []\n",
    "\n",
    "    input_df = pd.read_csv(file)\n",
    "\n",
    "    print(f'Getting lemmas for {file} file: {processed_files} | {files_to_process}' + \"\\n\")\n",
    "\n",
    "    for x in input_df.index:\n",
    "\n",
    "        token = input_df.loc[x, \"token\"]\n",
    "\n",
    "        lemma = input_df.loc[x, \"lemma\"]\n",
    "\n",
    "        warning = check_token(token)\n",
    "\n",
    "        if warning:\n",
    "\n",
    "            warnings_in_file.append([x, token])\n",
    "\n",
    "        if lemma is nan:\n",
    "\n",
    "            lemma = get_lemma(browser, file, x, token, logs)\n",
    "\n",
    "            print(f'Token {token}       lemma : {lemma}')\n",
    "\n",
    "            new_lemmas_in_file.append([x, token, lemma])\n",
    "\n",
    "            input_df.loc[x, \"lemma\"] = lemma\n",
    "\n",
    "    input_df.to_csv(processed_file)\n",
    "\n",
    "    # Building the warnings' file, if there are any, for the file on process.\n",
    "\n",
    "    if len(warnings_in_file) != 0:\n",
    "\n",
    "        print(f'Warnings found for {file} file. A report in {warnings_file}')\n",
    "\n",
    "        warnings_df = pd.DataFrame(warnings_in_file, columns=['line', 'token'])\n",
    "\n",
    "        warnings_df.to_csv(warnings_file)\n",
    "\n",
    "    new_lemmas_in_file_df = pd.DataFrame(new_lemmas_in_file, columns=['line', 'token', 'lemma'])\n",
    "\n",
    "    new_lemmas_in_file_df.to_csv(new_lemmas_file)\n",
    "\n",
    "    logs.close()\n",
    "\n",
    "browser.close()\n",
    "\n",
    "print(f'..... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
